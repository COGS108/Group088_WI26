{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "\n",
    "Contributions as of Project Proposal:\n",
    "- Michelle Lappin: Analysis, Data curation, Methodology, Project administration, Writing – original draft, Writing – review & editing\n",
    "- Andy Li: Analysis, Background research, Data curation, Conceptualization, Methodology, Writing – original draft, Writing – review & editing\n",
    "- Cheng-I Lin: Analysis, Data curation, Conceptualization, Methodology, Writing – original draft, Writing – review & editing\n",
    "- Tyler Ogawa: Analysis, Conceptualization, Project administration, Writing – original draft, Writing – review & editing\n",
    "- Navneet Sharma: Analysis, Background research, Project administration, Writing – original draft, Writing – review & editing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What factors can best predict the success of live-service shooters on Steam? Specifically, using pre-launch data (search interest, online activity, and developer/publisher) and early post-launch data (initial price and peak concurrent users), can we determine the factors that most accurately forecast long-term profitability (estimated revenue through review numbers), player retention (average playtime in the last two weeks), and community reception (final positive review percentage)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Background\n",
    "\n",
    "Steam, one of the most prominent online gaming platforms with millions of daily players, is home to thousands of shooting games. With the intense competition between video games of the same genre, each game must be able to portray and sell their uniqueness to emerge victorious in the rivalry between industries. A game can achieve this through creating outstanding graphical animations, developing special gameplay mechanics, reducing monetary costs, sharing connections to popular series or creators, and marketing to spread awareness. However, if a game fails to do so, it may not meet the expectations of the player community, resulting in what’s known as a flop (collectively acknowledged failures). Therefore, how do the developers and publishers of live-service shooting games anticipate a game’s commercial success of revenue and critical success of player reviews and engagement shortly after launch, or even before release, to prevent flops that can result in financial and occupational risks?\n",
    "\n",
    "Obviously, factors like price can greatly influence consumer behavior as there are over 1800 free to play shooter games on Steam, with Counter-Strike 2 and PUBG: BATTLEGROUNDS being the most widely known. Yet, even with more expensive price tags, games like Arc Raiders (launched at 40 USD) and Red Dead Redemption 2 (launched at 60 USD) still received great feedback in response to positive early reviews. To fully grasp the correlation between certain factors and a game’s success, our team will analyze the results of pre-launch data and early post-launch data to determine how to best achieve success. We were motivated in this research due to our familiarity in playing video games, especially those that include shooting aspects. Despite playing in the same category of video games, we each have our own personal favorites when it comes down to shooting games. Consequently, we noticed that although every game provides a different experience, we all seem to enjoy those different aspects of the game. Therefore, we are curious to see the impacts on success of the various characteristics a game features.\n",
    "\n",
    "### Prior Work\n",
    "Similar questions have been asked by several researchers in the past, for instance, by researcher and data scientist <a href=\"https://www.researchgate.net/publication/355110719_Predicting_the_Popularity_of_Games_on_Steam\">David Nabergoj</a>. David and his team sought out to predict the popularity of games on Steam. To elaborate, the study attempted to discover the relationship between the popularity of the game and its features. Using Bayesian models, the game's popularity was measured before and after its release, which was contingent on its price, storage size, supported languages, release date, and genre. Their findings concluded that a genre-based hierarchical model performed the best, as well as certain genres and early release dates were strongly associated with higher player counts.\n",
    "\n",
    "The dataset their model operated on consisted of games released after 2015. Gathered from three disparate sources, Steam API, Stream Spy, which offers data not available from Steam's API, and Steam DB, a historical database of player count. Price, and system requirements were the primary aim of their data wrangling procedure. Cheaper games are, generally, more popular, and the more storage a game requires, the greater the budget, inferring the higher the reputation of the game . Upon cleaning their data they were left with a dataset upwards of 8,000 games.\n",
    "\n",
    "The prediction aimed to correctly analyze the median player count by the second month upon the game's release. By utilizing simple regression models it was found that, not only were most games cheap and minimal in storage size, but overwhelmed by outliers as well. Certain categories such as developers and publishers were dropped from categorical features as there were too many confounding variables. The player counts peaked the first month after release, and numbers plateaued the second. Therefore, it can be said that the first month is paramount in predicting success. Marginal factors included supported languages, storage size, price, and the time at which the game was released.\n",
    "\n",
    "### References\n",
    "\n",
    "1. <a name=\"cite_note-1\"></a> [^](#cite_ref-1) Luisa, Andraž, Hartman, Jan, Nabergoj, David, Pahor, Samo, Rus, Marko, Stevanoski, Bozhidar, Demšar, Jure, & Štrumbelj, Erik. (2021). *Predicting the Popularity of Games on Steam.* arXiv. https://doi.org/10.48550/arXiv.2110.02896\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- 1. Revenue: We predict that pre-launch search interest will be the strongest predictor of estimated revenue. However, for free-to-play games, peak concurrent users will more accurately forecast revenue in the long term. This is because live-service games rely on recurring transactions for sustained revenue, and rely on a high volume of players.\n",
    "- 2. Retention: We predict that revenue will be strongly correlated with a game's initial price and less so with search interest. This is because the hype around a game spikes and dies down gradually over time (exponential decay), and financial investment will drive players to play a game for longer.\n",
    "- 3. Reception: We predict that an interaction between initial price and category count (number of features like Steam Achievements or Cloud Save) will correlate with the final positive review percentage. This is because games with a high price point yet low number of features will be perceived to be \"lacking polish\", and receive more negative reviews.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "### What we have fixed from last time\n",
    "To obtain pre-launch data, including the percentages of positive and negative reviews, we will use both the Steam Spy API and the Google Trends API via PyTrends. This will allow us to fetch the necessary pre-release data to effectively evaluate the initial success and online engagement of each game. For our dataset, we are narrowing Steam's game set to 200 randomly selected shooter games tagged as 'FPS'. Some games currently tagged as 'FPS' on the Steam market are inaccurately tagged, so we will manually remove these outliers to ensure data quality. Finally, all post-release data will be sourced from the Steam Spy API."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data overview\n",
    "\n",
    "- Dataset #1\n",
    "  - Dataset Name: Steam Web API\n",
    "  - Link to the dataset: https://steamcommunity.com/dev\n",
    "  - Number of observations: ~180,000\n",
    "  - Number of variables: 36\n",
    "  - Most relevant are: supported_languages, pc_requirements, platforms, genre, categories\n",
    "    - supported_langauges is stored in a string format containing the language name and some other texts. The other variables (pc_requirements, platforms, genres, and categories) are stored in a list of dictionaries that contain information about each category. These are important features as they provide the general information regarding the metadata of the games. For instance, we can compared how the various language supported or diffferent pc requirements can affect how players view the game, thus allowing us to see if which aspect of the game can boost its success.\n",
    "  - Shortcomings: Requires a steam account which has spent over $5 in steam. Also rate limits to 1.5s interval requests, making data processing and gathering tedious.\n",
    "- Datset #2\n",
    "  - Dataset Name: Google Trends\n",
    "  - Link to the dataset: https://trends.google.com/trends\n",
    "  - Number of observations: ~1 billion\n",
    "  - Number of variables: 1\n",
    "  - Most relevant are: search_interest\n",
    "    - Search interest is a relative, normalized metric (0–100) representing a topic's popularity compared to total search volume, not absolute search numbers. A score of 100 indicates peak popularity, 50 means half as popular, and 0 means insufficient data. This is a normalized value, making the comparison between different time periods possible. With this, we can filter the timeframe for pre-launch data that can imply the amount of followers and attentions the game has, providing a metric to how popular a game is.\n",
    "  - Shortcomings: Only has one variable. Requests also take a while because Google has undisclosed rate limits. Therefore, we need to randomly sample a small amount of games from our SteamSpy dataset so that we can reduce the runtime and have a cleaner dataset.\n",
    "- Dataset #3\n",
    "  - Dataset Name: SteamSpy\n",
    "  - Link to the dataset: https://steamspy.com/api.php\n",
    "  - Number of observations: ~65,000\n",
    "  - Number of variables: 20\n",
    "  - Most relevant are: initialprice, ccu, developer, publisher, positive, negative\n",
    "    - These are important features as they can be utilized as metrics for our game success indicator. The variable owners depict the range of individuals who own the game in string format, while ccu represents the peak concurrent users in integer format that signifies the maximum total number of players logged in the game during a single time frame. Combining with the variable initialprice (original US price in cents), we can calulate the estimated revenue in sales based on how many people bought the game. Prices of games can vary drastically, from less than 10 to more than 50 dollars depending on the types of games. Besides this, the metadata of the game, such as its developer (string), publisher (string), and the number of positive and negative reviews (interger counts) it received, can also help determine the public recognition and connotation toward the game.\n",
    "  - Shortcomings: Less accurate because it relies on people setting their profiles to public, since they're private by default. They scrape information from profiles, but with a fraction of the total data, they rely on a lot of statistical inference which can have errors.\n",
    "\n",
    "To combine these datasets, we start with #2. That one has only one variable so we simply add it as a column to #1. To merge the new #1 and #3, we will use descriptive data from the official API and merge it with variables like positive, negative, and ccu from SteamSpy—these variables don't exist in the official API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code every time when you're actively developing modules in .py files.  It's not needed if you aren't making modules\n",
    "#\n",
    "## this code is necessary for making sure that any modules we load are updated here \n",
    "## when their source code .py files are modified\n",
    "\n",
    "# Not necessary\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup code -- this only needs to be run once after cloning the repo!\n",
    "# this code downloads the data from its source to the `data/00-raw/` directory\n",
    "# if the data hasn't updated you don't need to do this again!\n",
    "\n",
    "# if you don't already have these packages (you should!) uncomment this line\n",
    "# %pip install requests tqdm\n",
    "\n",
    "# Not necessary\n",
    "# import sys\n",
    "# sys.path.append('./modules') # this tells python where to look for modules to import\n",
    "\n",
    "# import get_data # this is where we get the function we need to download data\n",
    "\n",
    "# replace the urls and filenames in this list with your actual datafiles\n",
    "# yes you can use Google drive share links or whatever\n",
    "# format is a list of dictionaries; \n",
    "# each dict has keys of \n",
    "#   'url' where the resource is located\n",
    "#   'filename' for the local filename where it will be stored \n",
    "# Not necessary\n",
    "# datafiles = [\n",
    "#     { 'url': 'https://raw.githubusercontent.com/fivethirtyeight/data/refs/heads/master/airline-safety/airline-safety.csv', 'filename':'airline-safety.csv'},\n",
    "#     { 'url': 'https://raw.githubusercontent.com/fivethirtyeight/data/refs/heads/master/bad-drivers/bad-drivers.csv', 'filename':'bad-drivers.csv'}\n",
    "# ]\n",
    "\n",
    "# get_data.get_raw(datafiles,destination_directory='data/00-raw/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code blocks above this one are unused since there's no convenient csv files on github.\n",
    "\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from pytrends.request import TrendReq\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "def steamspy_data():\n",
    "    # Setup target directory\n",
    "    output_dir = \"data/00-raw\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Use tag to filter by FPS genre\n",
    "    url = \"https://steamspy.com/api.php?request=tag&tag=FPS\"\n",
    "    \n",
    "    print(f\"Fetching data from SteamSpy...\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        data = response.json()\n",
    "        \n",
    "        # Filename to save to target directory\n",
    "        file_path = os.path.join(output_dir, \"steamspy.json\")\n",
    "        \n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(data, f, indent=4, ensure_ascii=False)\n",
    "            \n",
    "        print(f\"Successfully saved {len(data)} games to {file_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Already ran, dataset created\n",
    "# steamspy_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def official_data():\n",
    "    # Filename and name of SteamSpy file.\n",
    "    raw_path = \"data/00-raw/steamspy.json\"\n",
    "    output_path = \"data/00-raw/steamapi.json\"\n",
    "\n",
    "    with open(raw_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        steamspy_data = json.load(f)\n",
    "\n",
    "    # Random sample to save time\n",
    "    app_ids = list(steamspy_data.keys())\n",
    "    random.shuffle(app_ids)\n",
    "    target_ids = app_ids[:200]\n",
    "\n",
    "    # Storage dictionary\n",
    "    detailed_results = {}\n",
    "    \n",
    "    print(f\"Starting requests...\")\n",
    "    \n",
    "    for i, app_id in enumerate(target_ids):\n",
    "        # Steam Store API\n",
    "        url = f\"https://store.steampowered.com/api/appdetails?appids={app_id}\"\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            \n",
    "            if response.status_code == 429:\n",
    "                print(\"Rate limit hit! Sleeping for 30 seconds...\")\n",
    "                time.sleep(30)\n",
    "                continue\n",
    "                \n",
    "            data = response.json()\n",
    "            \n",
    "            if data and data[str(app_id)][\"success\"]:\n",
    "                game_info = data[str(app_id)][\"data\"]\n",
    "                detailed_results[app_id] = game_info\n",
    "                print(f\"[{i+1}/200] Fetched: {game_info.get('name')}\")\n",
    "            else:\n",
    "                print(f\"[{i+1}/200] Failed to get data for ID: {app_id}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching {app_id}: {e}\")\n",
    "        \n",
    "        # Try to avoid rate limits\n",
    "        time.sleep(1.5)\n",
    "\n",
    "    # Save results\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(detailed_results, f, indent=4, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"\\nFinished! Detailed data saved to {output_path}\")\n",
    "\n",
    "# Requires SteamSpy list to exist before running.\n",
    "# Already ran, dataset created\n",
    "# official_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def trends_data():\n",
    "    input_path = \"data/00-raw/steamapi.json\"\n",
    "    output_path = \"data/00-raw/trends.csv\"\n",
    "    \n",
    "    if not os.path.exists(input_path):\n",
    "        print(\"Error: steamapi.json not found.\")\n",
    "        return\n",
    "\n",
    "    with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        games_data = json.load(f)\n",
    "\n",
    "    pytrends = TrendReq(hl=\"en-US\", tz=360)\n",
    "    results = []\n",
    "\n",
    "    print(f\"Processing {len(games_data)} games...\")\n",
    "\n",
    "    for i, (app_id, details) in enumerate(games_data.items()):\n",
    "        game_name = details.get(\"name\")\n",
    "        release_info = details.get(\"release_date\", {})\n",
    "        date_str = release_info.get(\"date\")\n",
    "    \n",
    "        if not date_str:\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            # Convert to datetime\n",
    "            launch_date = pd.to_datetime(date_str)\n",
    "            \n",
    "            # Timeframe is 30 days before launch to launch day\n",
    "            start_date = (launch_date - timedelta(days=30)).strftime(\"%Y-%m-%d\")\n",
    "            end_date = launch_date.strftime(\"%Y-%m-%d\")\n",
    "            timeframe = f\"{start_date} {end_date}\"\n",
    "            \n",
    "            print(f\"[{i+1}/200] Fetching Trends for: {game_name} ({timeframe})\")\n",
    "\n",
    "            # Search for interest over time\n",
    "            pytrends.build_payload([game_name], cat=0, timeframe=timeframe, geo=\"\")\n",
    "            df = pytrends.interest_over_time()\n",
    "\n",
    "            avg_interest = 0\n",
    "            if not df.empty and game_name in df.columns:\n",
    "                avg_interest = df[game_name].mean()\n",
    "\n",
    "            # Append to our list\n",
    "            results.append({\n",
    "                \"name\": game_name,\n",
    "                \"launch_date\": end_date,\n",
    "                \"search_interest\": float(avg_interest)\n",
    "            })\n",
    "            \n",
    "            print(f\"Saved: {game_name} | Score: {avg_interest}\")\n",
    "\n",
    "            # Save every time\n",
    "            pd.DataFrame(results).to_csv(output_path, index=False)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {game_name}: {e}\")\n",
    "        \n",
    "        # To avoid harsh rate limits\n",
    "        time.sleep(5)\n",
    "\n",
    "    print(f\"Done! Trends saved to {output_path}\")\n",
    "\n",
    "# Needs `pip install pytrends`\n",
    "# Already ran, dataset created\n",
    "# trends_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steam Shooter Performance & Market Success Dataset\n",
    "\n",
    "This dataset integrates metadata and performance metrics from the Steam Web API, SteamSpy, and Google Trends to analyze the commercial and critical success of shooter games. It combines pre-launch interest with post-launch outcomes such as financial revenue, player retention, and community sentiment. The data is structured at the individual game level, allowing for a multifaceted look at how marketing \"hype\" translates into long-term sustainability on the Steam platform.\n",
    "\n",
    "Key Variables:\n",
    "- Estimated Revenue (USD): This is a calculated heuristic which uses review counts as a proxy for sales. For paid games, it is calculated as #Reviews x 30 x Price, while for free-to-play games, a multiplier of 75 is used to account for in-game microtransactions. While not an absolute measurement, it provides a relative scale of commercial success.\n",
    "- Search Interest (Index 0-100): Sourced from Google Trends, this represents relative search volume normalized to the peak popularity within 30 days before launch. A value of 100 represents the peak of public interest, while 50 indicates the topic was half as popular.\n",
    "- Community Reception (Percentage 0.0-1.0): Calculated as the number of positive reviews divided by total reviews. A value of 0.90 or higher generally corresponds to an \"Overwhelmingly Positive\" rating on Steam, whereas values below 0.40 indicate \"Mostly Negative\".\n",
    "- Player Retention (Minutes): Represented by the average_2weeks variable, this measures the average time in minutes players spent in-game over the most recent 2 week period.\n",
    "- CCU (Count): Peak Concurrent Users. This represents the highest number of players logged into the game simultaneously. For shooters, below 500 is unhealthy and over 10,000 is extreme success.\n",
    "\n",
    "Data Limitations and Concerns:\n",
    "- SteamSpy data is the source for review counts and CCU, but because Steam user profiles are private by default, SteamSpy uses sampling and statistical inference to estimate these numbers. This introduces a margin of error, particularly for niche games with smaller player bases where the sample size is lower.\n",
    "- The estimated_revenue calculation relies on the assumption that a consistent ratio of players leaves reviews. However, this ratio can fluctuate wildly based on a game's reputation or community sentiment; a frustrated community might leave more reviews (negative) than a content one, potentially bloating the revenue estimate for poorly received games.\n",
    "- Google Trends data for search interest can be noisy if a game has a generic title (e.g., \"Squad\" or \"Control\"). While efforts are made to clean the names, some search volume may reflect general vocabulary rather than interest in the specific video game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "trends_df = pd.read_csv(\"data/00-raw/trends.csv\")\n",
    "with open(\"data/00-raw/steamapi.json\", \"r\") as f:\n",
    "    api_data = json.load(f)\n",
    "with open(\"data/00-raw/steamspy.json\", \"r\") as f:\n",
    "    spy_data = json.load(f)\n",
    "\n",
    "# Process JSON\n",
    "api_records = []\n",
    "for appid, d in api_data.items():\n",
    "    if d:\n",
    "        api_records.append({\n",
    "            \"appid\": d.get(\"steam_appid\"),\n",
    "            \"name\": d.get(\"name\"),\n",
    "            \"is_free\": d.get(\"is_free\"),\n",
    "            \"developers\": \", \".join(d.get(\"developers\", [])),\n",
    "            \"publishers\": \", \".join(d.get(\"publishers\", [])),\n",
    "            \"categories_count\": len(d.get(\"categories\", []))\n",
    "        })\n",
    "api_df = pd.DataFrame(api_records)\n",
    "\n",
    "# Process JSON again\n",
    "spy_records = []\n",
    "for appid, d in spy_data.items():\n",
    "    if d:\n",
    "        spy_records.append({\n",
    "            \"appid\": d.get(\"appid\"),\n",
    "            \"positive\": d.get(\"positive\", 0),\n",
    "            \"negative\": d.get(\"negative\", 0),\n",
    "            \"initialprice\": float(d.get(\"initialprice\", 0)) / 100.0,\n",
    "            \"price\": float(d.get(\"price\", 0)) / 100.0,\n",
    "            \"ccu\": d.get(\"ccu\", 0),\n",
    "            \"average_2weeks\": d.get(\"average_2weeks\", 0)\n",
    "        })\n",
    "spy_df = pd.DataFrame(spy_records)\n",
    "\n",
    "# Merge\n",
    "games_meta = pd.merge(api_df, spy_df, on=\"appid\", how=\"inner\")\n",
    "trends_df[\"name_clean\"] = trends_df[\"name\"].str.lower().str.strip()\n",
    "games_meta[\"name_clean\"] = games_meta[\"name\"].str.lower().str.strip()\n",
    "final_df = pd.merge(trends_df, games_meta, on=\"name_clean\", how=\"inner\")\n",
    "\n",
    "# Target variables\n",
    "final_df[\"total_reviews\"] = final_df[\"positive\"] + final_df[\"negative\"]\n",
    "final_df[\"estimated_revenue\"] = np.where(\n",
    "    final_df[\"is_free\"],\n",
    "    final_df[\"total_reviews\"] * 75,\n",
    "    final_df[\"total_reviews\"] * 30 * final_df[\"price\"]\n",
    ")\n",
    "final_df[\"community_reception\"] = (final_df[\"positive\"] / final_df[\"total_reviews\"]).fillna(0)\n",
    "final_df[\"player_retention\"] = final_df[\"average_2weeks\"]\n",
    "\n",
    "# Tidy and save\n",
    "final_cols = [\n",
    "    \"name_x\", \"launch_date\", \"search_interest\", \"developers\", \"publishers\",\n",
    "    \"categories_count\", \"initialprice\", \"ccu\", \"is_free\",\n",
    "    \"estimated_revenue\", \"community_reception\", \"player_retention\"\n",
    "]\n",
    "processed_df = final_df[final_cols].rename(columns={\"name_x\": \"name\"})\n",
    "print('Final Dataset Shape:')\n",
    "print(processed_df.shape)\n",
    "print('Missing Values per Column:')\n",
    "print(processed_df.isna().sum())\n",
    "output_dir = \"data/02-processed\"\n",
    "file_name = \"shooter_performance_data.csv\"\n",
    "full_path = os.path.join(output_dir, file_name)\n",
    "processed_df.to_csv(full_path, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we fixed: For our ethics section, we have elaborated on and expanded the possible ethical concerns that may arise while completing this project. We have also filled in sections that were previously left blank. \n",
    "\n",
    "Here is a [list of real world examples](https://deon.drivendata.org/examples/) for each item in the checklist that can refer to.\n",
    "\n",
    "[![Deon badge](https://img.shields.io/badge/ethics%20checklist-deon-brightgreen.svg?style=popout-square)](http://deon.drivendata.org/)\n",
    "\n",
    "### A. Data Collection\n",
    " - [X] **A.1 Informed consent**: If there are human subjects, have they given informed consent, where subjects affirmatively opt-in and have a clear understanding of the data uses to which they consent?\n",
    "\n",
    "> All user data originates from the Steam API, where users agree to data usage through Steam’s Privacy Policy and EULA before creating accounts. We only access publicly available information permitted under these agreements and do not collect private or restricted user data.\n",
    "\n",
    " - [X] **A.2 Collection bias**: Have we considered sources of bias that could be introduced during data collection and survey design and taken steps to mitigate those?\n",
    "\n",
    "> We recognize that Steam users, FPS players specifically, may not represent the broader gaming population. FPS communities tend to skew toward certain demographics like gender and age, which may bias measures of “success.” We account for this by interpreting findings as specific to the Steam FPS ecosystem rather than generalizing to all gamers. \n",
    "\n",
    " - [X] **A.3 Limit PII exposure**: Have we considered ways to minimize exposure of personally identifiable information (PII) for example through anonymization or not collecting information that isn't relevant for analysis?\n",
    "\n",
    "> Usernames may appear in raw datasets as identifiers but are only used internally for deduplication and record matching. All personally identifiable information is removed or anonymized prior to analysis and reporting to prevent traceability to individuals. \n",
    "\n",
    " - [X] **A.4 Downstream bias mitigation**: Have we considered ways to enable testing downstream results for biased outcomes (e.g., collecting data on protected group status like race or gender)?\n",
    "> Because demographic attributes such as race or gender are not available in the dataset, we acknowledge that we cannot directly test for group-level disparities. We therefore avoid making claims about demographic fairness and limit conclusions strictly to observable behavioral metrics.\n",
    "\n",
    "### B. Data Storage\n",
    " - [X] **B.1 Data security**: Do we have a plan to protect and secure data (e.g., encryption at rest and in transit, access controls on internal users and third parties, access logs, and up-to-date software)?\n",
    "\n",
    "> All datasets are stored on secured, access-controlled systems. Only project members have access, and files are shared through encrypted platforms to minimize risk of unauthorized exposure.\n",
    "\n",
    " - [X] **B.2 Right to be forgotten**: Do we have a mechanism through which an individual can request their personal information be removed?\n",
    "\n",
    "> Since we use publicly available data and anonymize it before analysis, individuals are not directly identifiable. If requested, any raw records associated with a user can be removed from local copies of the dataset.\n",
    "\n",
    " - [X] **B.3 Data retention plan**: Is there a schedule or plan to delete the data after it is no longer needed?\n",
    "\n",
    "> Data will be retained only for the duration of the project. Unnecessary or intermediate files will be deleted, and all raw data will be securely removed after analysis is complete. \n",
    "\n",
    "### C. Analysis\n",
    " - [X] **C.1 Missing perspectives**: Have we sought to address blindspots in the analysis through engagement with relevant stakeholders (e.g., checking assumptions and discussing implications with affected communities and subject matter experts)?\n",
    "\n",
    "> We discuss assumptions within the team and consider how different stakeholders (developers, players, underrepresented groups) might interpret the results to reduce blind spots in our conclusions.\n",
    "\n",
    " - [X] **C.2 Dataset bias**: Have we examined the data for possible sources of bias and taken steps to mitigate or address these biases (e.g., stereotype perpetuation, confirmation bias, imbalanced classes, or omitted confounding variables)?\n",
    "\n",
    ">We examine the dataset for potential sources of bias such as overrepresentation of highly popular games, underrepresentation of niche titles, missing values, and class imbalance. Because Steam users and FPS players may not reflect the broader gaming population, we interpret results within this context and avoid generalizing beyond the platform. Where appropriate, we use normalization or stratified analysis to reduce skewed outcomes.\n",
    "\n",
    " - [X] **C.3 Honest representation**: Are our visualizations, summary statistics, and reports designed to honestly represent the underlying data?\n",
    "\n",
    "> Visualizations and summaries are designed to avoid misleading scales. We report uncertainty and limitations alongside results.\n",
    "\n",
    " - [X] **C.4 Privacy in analysis**: Have we ensured that data with PII are not used or displayed unless necessary for the analysis?\n",
    "\n",
    ">Personally identifiable information, including usernames, is used only temporarily for internal data cleaning and record matching. All identifying information is removed or anonymized before analysis and is never included in visualizations, reports, or shared outputs. Results are presented only in aggregated form to protect individual privacy.\n",
    "\n",
    "> Data used from Steam users will be identified as their public usernames, but that information will not be publicly shared in our data. Usernames are used as a unique identifier, as we go through all the datasets, but are completely irrelevant and will not be presented in our findings. \n",
    "\n",
    " - [X] **C.5 Auditability**: Is the process of generating the analysis well documented and reproducible if we discover issues in the future?\n",
    "\n",
    "> All preprocessing and modeling steps are documented and reproducible through code and version control to allow future review or correction.\n",
    "\n",
    "### D. Modeling\n",
    " - [X] **D.1 Proxy discrimination**: Have we ensured that the model does not rely on variables or proxies for variables that are unfairly discriminatory?\n",
    "\n",
    ">We avoid using features that may indirectly encode sensitive attributes. Only gameplay and performance-related metrics are included.\n",
    "\n",
    " - [X] **D.2 Fairness across groups**: Have we tested model results for fairness with respect to different affected groups (e.g., tested for disparate error rates)?\n",
    "\n",
    "> Although demographic labels are unavailable, we test model performance across different game sizes and popularity levels to ensure predictions are not disproportionately skewed toward certain subsets.\n",
    "\n",
    " - [X] **D.3 Metric selection**: Have we considered the effects of optimizing for our defined metrics and considered additional metrics?\n",
    "\n",
    ">We evaluate multiple performance metrics rather than optimizing for a single score to avoid misleading conclusions. For example, we consider accuracy alongside precision/recall or error-based measures to ensure the model performs consistently across different scenarios and does not favor one type of outcome at the expense of others.\n",
    "\n",
    " - [X] **D.4 Explainability**: Can we explain in understandable terms a decision the model made in cases where a justification is needed?\n",
    "\n",
    ">We prioritize interpretable modeling approaches and provide clear explanations of how predictions are generated. Feature importance and model behavior are documented so stakeholders can understand which factors influence outcomes and can question or validate decisions when needed.\n",
    "\n",
    " - [X] **D.5 Communicate limitations**: Have we communicated the shortcomings, limitations, and biases of the model to relevant stakeholders in ways that can be generally understood?\n",
    "\n",
    ">We explicitly communicate that predictions are correlational, depend on historical Steam data, and may not generalize to other platforms or future trends.\n",
    "\n",
    "### E. Deployment\n",
    " - [X] **E.1 Monitoring and evaluation**: Do we have a clear plan to monitor the model and its impacts after it is deployed (e.g., performance monitoring, regular audit of sample predictions, human review of high-stakes decisions, reviewing downstream impacts of errors or low-confidence decisions, testing for concept drift)?\n",
    "\n",
    ">If deployed, the model’s performance would be monitored regularly to detect performance degradation, bias, or changes in data patterns over time like new gaming trends or shifts in player behavior. Periodic evaluations and retraining would be conducted to ensure the model remains accurate, fair, and aligned with its intended purpose.\n",
    "\n",
    " - [X] **E.2 Redress**: Have we discussed with our organization a plan for response if users are harmed by the results (e.g., how does the data science team evaluate these cases and update analysis and models to prevent future harm)?\n",
    "\n",
    "> If harm or misuse is identified, we will investigate, adjust the model, or remove problematic features.\n",
    "\n",
    " - [X] **E.3 Roll back**: Is there a way to turn off or roll back the model in production if necessary?\n",
    "\n",
    ">Deployment would allow the model to be disabled or reverted to previous versions if issues arise.\n",
    "\n",
    " - [X] **E.4 Unintended use**: Have we taken steps to identify and prevent unintended uses and abuse of the model and do we have a plan to monitor these once the model is deployed?\n",
    "\n",
    ">We caution that predictions should inform analysis rather than replace human judgment, reducing the risk of misuse in decision-making.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Expectations "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Communication: Will be held through a Discord group chat. Regarding frequency, a response to a message should be expected within 24 hours. Meetings should be weekly, virtually, or in-person.\n",
    "- Tone: Needs to be to the point, but also polite. The heart behind discussion should be to contribute positively to the project while not being personal. Likewise, criticism is permitted but should be constructive to the group effort.\n",
    "- Decision making: Major decisions should be addressed before the whole group. If decision conflicts arise, a majority vote should make the decision. \n",
    "- Tasks: Should be initially voluntary, that is, if someone feels more comfortable/knowledgeable than others at a certain task, they should take it. Leftover roles can be assigned to fill tasks.\n",
    "- Literal conflicts: Initially can be mentioned in chat to address issues that might arise. If still not resolved, it should be addressed in a call to avoid misinterpretations over text."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Timeline Proposal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we fixed: From last time we have elaborated on what each check-in will focus on. Opposed to \"general check-ins\", we have updated our timeline toinclude specific issues and checkpoints, such as making charts, scraping data, and much more. \n",
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 2/2/26  |  2 PM | Review any potential concerns with project proposal. Ensure that all of the variables we mentioned in our proposal seem accessible and lead to meaningful results. Assign specific tasks to each teammate. Search for databases. | Final revisions, review and submission of proposals. Ensure everyone is up to date. Discuss project strengths/weaknesses and confirm task assignments.| \n",
    "| 2/9/26  |  2 PM | Check in and make sure that the individual tasks assignment in the previous meetings were completed. | Update each other on progress. Decide best methods to handle and scrape data regarding Steam databases.| \n",
    "| 2/16/26  |  2 PM | Investigate data through SteamSpy to get estimates of variables (revenue, feedback & reviews) and look for promising data. Narrow down which databases work best for which variables to account for. Verify integrity and compatibility of the player data. | Share results with the team. Investigate random samples, merge databases and calculate revenues. Discuss other variables to pivot to (early access/beta access player numbers) since access of some variables (pre-release data) is infavorable. Assign data wrangling and data description tasks.| \n",
    "| 2/23/26  | 2 PM  | Review previously mentioned goals and tasks for meeting. Individually evaluate data presentation ideas, charts, and organization. Vote which ones work best for our project | Report any issues that come up, being mindful of any problems which the project depends on to move forward. If important issues arise, rearrange workload, putting them at first priority. Make an emergency meeting one week from then. For example, if a team member is struggling with extrapolating information from certain data, or we find that one task demands more attention than others/is more difficult than we had initially planned, we will reallocate our efforts towards accomplishing that. Once that is done, make another checkpoint. |\n",
    "| 3/2/26 (If we had aforementioned issues)  | 2 PM  | Address the aforementioned issues | Check in to make sure the issues are no longer a problem. Reevaluate priorities and divide tasks once more accordingly.  |\n",
    "| 3/9/26  | 2 PM  | Work on slideshow by generating graphs and visuals that adequately presents our data. Write descriptions that explains correlations between our visuals and our data. |Have entire team ensure that visuals, tests and data makes sense (Compare with third-party websites with similar topics and research). Finalize Slideshow. Make any adjustments if needed. Plan and start creating a video to present the data. |\n",
    "| 3/17/26  | 2 PM  |Finalize/Turn in project and video. |Confirm everyone is satisfied with the project and that all aspects are completed including the project video.  |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "16b860a9f5fc21240e9d88c0ee13691518c3ce67be252e54a03b9b5b11bd3c7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
